{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-10-25T18:34:55.131063Z",
     "iopub.status.busy": "2023-10-25T18:34:55.130457Z",
     "iopub.status.idle": "2023-10-25T18:35:01.757921Z",
     "shell.execute_reply": "2023-10-25T18:35:01.757062Z",
     "shell.execute_reply.started": "2023-10-25T18:34:55.131024Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n",
    "\n",
    "from typing import Optional, Union\n",
    "import pandas as pd, numpy as np, torch\n",
    "from datasets import Dataset\n",
    "from dataclasses import dataclass\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import EarlyStoppingCallback\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer\n",
    "\n",
    "NUM_TRAIN_SAMPLES = 1_024\n",
    "FREEZE_LAYERS = 18\n",
    "FREEZE_EMBEDDINGS = True\n",
    "MAX_INPUT = 256\n",
    "MODEL = 'microsoft/deberta-v3-large'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-25T18:35:01.759634Z",
     "iopub.status.busy": "2023-10-25T18:35:01.759214Z",
     "iopub.status.idle": "2023-10-25T18:35:05.993021Z",
     "shell.execute_reply": "2023-10-25T18:35:05.991709Z",
     "shell.execute_reply.started": "2023-10-25T18:35:01.759597Z"
    }
   },
   "outputs": [],
   "source": [
    "df_valid = pd.read_csv('/kaggle/input/60k-data-with-context-v2/train_with_context2.csv')\n",
    "print('Validation data size:', df_valid.shape )\n",
    "df_train = pd.read_csv('/kaggle/input/60k-data-with-context-v2/all_12_with_context2.csv')\n",
    "df_train = df_train.drop(columns=\"source\")\n",
    "df_train = df_train.fillna('').sample(NUM_TRAIN_SAMPLES)\n",
    "print('Train data size:', df_train.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-25T18:35:05.995051Z",
     "iopub.status.busy": "2023-10-25T18:35:05.994416Z",
     "iopub.status.idle": "2023-10-25T18:35:06.001741Z",
     "shell.execute_reply": "2023-10-25T18:35:06.000852Z",
     "shell.execute_reply.started": "2023-10-25T18:35:05.995014Z"
    }
   },
   "outputs": [],
   "source": [
    "option_to_index = {option: idx for idx, option in enumerate('ABCDE')}\n",
    "index_to_option = {v: k for k,v in option_to_index.items()}\n",
    "\n",
    "def preprocess(example):\n",
    "    first_sentence = [ \"[CLS] \" + example['context'] ] * 5\n",
    "    second_sentences = [\" #### \" + example['prompt'] + \" [SEP] \" + example[option] + \" [SEP]\" for option in 'ABCDE']\n",
    "    tokenized_example = tokenizer(first_sentence, second_sentences, truncation='only_first', \n",
    "                                  max_length=MAX_INPUT, add_special_tokens=False)\n",
    "    tokenized_example['label'] = option_to_index[example['answer']]\n",
    "    return tokenized_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-25T18:35:06.004725Z",
     "iopub.status.busy": "2023-10-25T18:35:06.004445Z",
     "iopub.status.idle": "2023-10-25T18:35:06.019451Z",
     "shell.execute_reply": "2023-10-25T18:35:06.018734Z",
     "shell.execute_reply.started": "2023-10-25T18:35:06.004702Z"
    }
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "from typing import Optional, Union\n",
    "import torch\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForMultipleChoice:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs for multiple choice received.\n",
    "    \"\"\"\n",
    "\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features):\n",
    "        label_name = \"label\" if \"label\" in features[0].keys() else \"labels\"\n",
    "        labels = [feature.pop(label_name) for feature in features]\n",
    "        batch_size = len(features)\n",
    "        num_choices = len(features[0][\"input_ids\"])\n",
    "        flattened_features = [\n",
    "            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features\n",
    "        ]\n",
    "        flattened_features = sum(flattened_features, [])\n",
    "\n",
    "        batch = self.tokenizer.pad(\n",
    "            flattened_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n",
    "        batch[\"labels\"] = torch.tensor(labels, dtype=torch.int64)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-25T18:35:06.021211Z",
     "iopub.status.busy": "2023-10-25T18:35:06.020625Z",
     "iopub.status.idle": "2023-10-25T18:35:07.269102Z",
     "shell.execute_reply": "2023-10-25T18:35:07.268127Z",
     "shell.execute_reply.started": "2023-10-25T18:35:06.021178Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "dataset_valid = Dataset.from_pandas(df_valid)\n",
    "dataset_train = Dataset.from_pandas(df_train)\n",
    "dataset_train = dataset_train.remove_columns([\"__index_level_0__\"])\n",
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-25T18:35:07.271031Z",
     "iopub.status.busy": "2023-10-25T18:35:07.270396Z",
     "iopub.status.idle": "2023-10-25T18:35:27.563057Z",
     "shell.execute_reply": "2023-10-25T18:35:27.562053Z",
     "shell.execute_reply.started": "2023-10-25T18:35:07.270995Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenized_dataset_valid = dataset_valid.map(preprocess, remove_columns=['prompt', 'context', 'A', 'B', 'C', 'D', 'E', 'answer'])\n",
    "tokenized_dataset_train = dataset_train.map(preprocess, remove_columns=['prompt', 'context', 'A', 'B', 'C', 'D', 'E', 'answer'])\n",
    "tokenized_dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-25T18:35:27.564529Z",
     "iopub.status.busy": "2023-10-25T18:35:27.564205Z",
     "iopub.status.idle": "2023-10-25T18:35:32.188566Z",
     "shell.execute_reply": "2023-10-25T18:35:32.187568Z",
     "shell.execute_reply.started": "2023-10-25T18:35:27.564504Z"
    }
   },
   "outputs": [],
   "source": [
    "model = AutoModelForMultipleChoice.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-25T18:35:32.190374Z",
     "iopub.status.busy": "2023-10-25T18:35:32.189934Z",
     "iopub.status.idle": "2023-10-25T18:35:32.198688Z",
     "shell.execute_reply": "2023-10-25T18:35:32.197821Z",
     "shell.execute_reply.started": "2023-10-25T18:35:32.190336Z"
    }
   },
   "outputs": [],
   "source": [
    "if FREEZE_EMBEDDINGS:\n",
    "    print('Freezing embeddings.')\n",
    "    for param in model.deberta.embeddings.parameters():\n",
    "        param.requires_grad = False\n",
    "if FREEZE_LAYERS>0:\n",
    "    print(f'Freezing {FREEZE_LAYERS} layers.')\n",
    "    for layer in model.deberta.encoder.layer[:FREEZE_LAYERS]:\n",
    "        for param in layer.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-25T18:35:32.200276Z",
     "iopub.status.busy": "2023-10-25T18:35:32.199899Z",
     "iopub.status.idle": "2023-10-25T18:35:32.213624Z",
     "shell.execute_reply": "2023-10-25T18:35:32.212788Z",
     "shell.execute_reply.started": "2023-10-25T18:35:32.200218Z"
    }
   },
   "outputs": [],
   "source": [
    "def map_at_3(predictions, labels):\n",
    "    map_sum = 0\n",
    "    pred = np.argsort(-1*np.array(predictions),axis=1)[:,:3]\n",
    "    for x,y in zip(pred,labels):\n",
    "        z = [1/i if y==j else 0 for i,j in zip([1,2,3],x)]\n",
    "        map_sum += np.sum(z)\n",
    "    return map_sum / len(predictions)\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions = p.predictions.tolist()\n",
    "    labels = p.label_ids.tolist()\n",
    "    return {\"map@3\": map_at_3(predictions, labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-25T18:35:32.215616Z",
     "iopub.status.busy": "2023-10-25T18:35:32.214941Z",
     "iopub.status.idle": "2023-10-25T18:35:32.288424Z",
     "shell.execute_reply": "2023-10-25T18:35:32.287601Z",
     "shell.execute_reply.started": "2023-10-25T18:35:32.215579Z"
    }
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    warmup_ratio=0.1, \n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=2,\n",
    "    report_to='none',\n",
    "    output_dir = f'./checkpoints_2',\n",
    "    overwrite_output_dir=True,\n",
    "    fp16=True,\n",
    "    gradient_accumulation_steps=8,\n",
    "    logging_steps=25,\n",
    "    evaluation_strategy='steps',\n",
    "    eval_steps=25,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=25,\n",
    "    load_best_model_at_end=False,\n",
    "    metric_for_best_model='map@3',\n",
    "    lr_scheduler_type='cosine',\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-25T18:35:32.289914Z",
     "iopub.status.busy": "2023-10-25T18:35:32.289568Z",
     "iopub.status.idle": "2023-10-25T18:44:56.811101Z",
     "shell.execute_reply": "2023-10-25T18:44:56.806895Z",
     "shell.execute_reply.started": "2023-10-25T18:35:32.28988Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizer),\n",
    "    train_dataset=tokenized_dataset_train,\n",
    "    eval_dataset=tokenized_dataset_valid,\n",
    "    compute_metrics = compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model(f'model_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
